<!DOCTYPE html>
<html>
<head>
  <title>Cross-Validation</title>
  <meta charset="utf-8">
  <meta name="description" content="Cross-Validation">
  <meta name="author" content="Adam J Sullivan">
  <meta name="generator" content="slidify" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/default.css" media="all" >
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/phone.css" 
    media="only screen and (max-device-width: 480px)" >
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/slidify.css" >
  <link rel="stylesheet" href="libraries/highlighters/highlight.js/css/github.css" />
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->  <link rel=stylesheet href="libraries/widgets/quiz/css/demo.css"></link>
<link rel=stylesheet href="libraries/widgets/bootstrap/css/bootstrap.css"></link>
<link rel=stylesheet href="libraries/widgets/interactive/css/aceeditor.css"></link>
<link rel=stylesheet href="./assets/css/ribbons.css"></link>
<link rel=stylesheet href="./assets/css/style.css"></link>

  
  <!-- Grab CDN jQuery, fall back to local if offline -->
  <script src="http://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.7.min.js"></script>
  <script>window.jQuery || document.write('<script src="libraries/widgets/quiz/js/jquery.js"><\/script>')</script> 
  <script data-main="libraries/frameworks/io2012/js/slides" 
    src="libraries/frameworks/io2012/js/require-1.0.8.min.js">
  </script>
  
  

</head>
<body style="opacity: 0">
  <slides class="layout-widescreen">
    
    <!-- LOGO SLIDE -->
      <slide class="nobackground">
    <article class="flexbox vcenter">
      <span>
        <img width='300px' src="assets/img/publichealthlogo.png">
      </span>
    </article>
  </slide>
    <slide class="title-slide segue nobackground">
  <aside class="gdbar">
    <img src="assets/img/publichealthlogo.png">
  </aside>
  <hgroup class="auto-fadein">
    <h1>Cross-Validation</h1>
    <h2></h2>
    <p>Adam J Sullivan<br/>Assistant Professor of Biostatistics<br/>Brown University</p>
  </hgroup>
  <article></article>  
</slide>
    

    <!-- SLIDES -->
    <slide class="segue" id="slide-1" style="background:grey;">
  <hgroup>
    <h1>Cross validation</h1>
    <hr>
  </hgroup>
  <article data-timings="">
    
    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Cross Validation</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>One important concept in statistics and data science is cross validation. </li>
<li>This method can help us understand the errors present in our data. </li>
<li>It is often used for predictive modeling and validating other models. </li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Motivation with k-nearest neighbors</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>We will begin by considering the concept of k-nearest neighbors. </li>
<li>Let&#39;s explore some data first. </li>
</ul>

<pre><code class="r">library(tidyverse)
library(dslabs)
data(&quot;mnist_27&quot;)
mnist_27$test%&gt;% ggplot(aes(x_1, x_2, color = y)) +  geom_point()
</code></pre>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Motivation with k-nearest neighbors</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <p><img src="figure/unnamed-chunk-2-1.png" alt="plot of chunk unnamed-chunk-2"></p>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Why K-Nearest Neighbors</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>This is a non-parametric classification method.</li>
<li>We can use this to help separate out values. </li>
<li>In practice this can be used to match a new value with the closest old values. </li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>What are we doing?</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>We will use these data to estimate the conditional probability function 
\[
p(x_1, x_2) = \mbox{Pr}(Y=1 \mid X_1=x_1 , X_2 = x_2).
\]</li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>How do we do this?</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>First we define the distance between all observations based on the features. </li>
<li>Then, for any point \((x_1,x_2)\) for which we want an estimate of \(p(x_1, x_2)\), we look for the \(k\) nearest points to \((x_1,x_2)\) and then take an average of the 0s and 1s associated with these points. </li>
<li>We refer to the set of points used to compute the average as the <em>neighborhood</em>.</li>
<li>The larger your \(k\), the smoother the estimates. </li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2><code>caret</code> package in R</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>To implement the algorithm, we can use the <code>knn3</code> function from the <strong>caret</strong> package. </li>
</ul>

<pre><code class="r">library(caret)
knn_fit &lt;- knn3(y ~ ., data = mnist_27$train, k=5)
</code></pre>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>What do we get ?</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>The <code>predict</code> function for <code>knn</code> produces a probability for each class.</li>
<li>We keep the probability of being a 7 as the estimate \(\hat{p}(x_1, x_2)\)</li>
</ul>

<pre><code class="r">y_hat_knn &lt;- predict(knn_fit, mnist_27$test, type = &quot;class&quot;)
confusionMatrix(data = y_hat_knn, reference = mnist_27$test$y)$overall[&quot;Accuracy&quot;]
</code></pre>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>What do we get ?</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <pre><code>## Accuracy 
##    0.815
</code></pre>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Comparison to Linear Regression</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Let&#39;s see if linear regression could work: </li>
</ul>

<pre><code class="r">fit_lm &lt;- mnist_27$train %&gt;% mutate(y = ifelse(y == 7, 1, 0)) %&gt;% lm(y ~ x_1 + x_2, data = .)
p_hat_lm &lt;- predict(fit_lm, mnist_27$test)
y_hat_lm &lt;- factor(ifelse(p_hat_lm &gt; 0.5, 7, 2))
confusionMatrix(data = y_hat_lm, reference = mnist_27$test$y)$overall[&quot;Accuracy&quot;]
</code></pre>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Comparison to Linear Regression</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <pre><code>## Accuracy 
##     0.75
</code></pre>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Comparison to Linear Regression</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>kNN doe better than regression.</li>
<li> To see why this is case, we will plot \(\hat{p}(x_1, x_2)\) and compare it to the the true conditional probability \(p(x_1, x_2)\):</li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Comparison Plots</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <p><img src="figure/knn-fit-1.png" title="plot of chunk knn-fit" alt="plot of chunk knn-fit" width="70%" /></p>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Why does it work?</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>We can see that the relationship is non-linear. </li>
<li>Some of our areas and colors do not make sense though. </li>
<li>This is what we call overfitting. </li>
<li>Over-fitting is when the result works really well in one set of data but not as well in newer data. </li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Viewing Overfitting</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">y_hat_knn &lt;- predict(knn_fit, mnist_27$train, type = &quot;class&quot;)
confusionMatrix(data = y_hat_knn, reference = mnist_27$train$y)$overall[&quot;Accuracy&quot;]

y_hat_knn &lt;- predict(knn_fit, mnist_27$test, type = &quot;class&quot;)
confusionMatrix(data = y_hat_knn, reference = mnist_27$test$y)$overall[&quot;Accuracy&quot;]
</code></pre>

<pre><code>## Accuracy 
##    0.882 
## Accuracy 
##    0.815
</code></pre>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Over-fitting</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Over-fitting with kNN is the worst when \(k=1\). </li>
<li>This is because the estimate for each \((x_1, x_2)\) in the training set is obtained with just the \(y\) corresponding to that point. </li>
<li>In this case, if the \((x_1, x_2)\) are unique, we will obtain perfect accuracy in the training set because each point is used to predict itself. </li>
<li>however, this will fail if the new points are not in the training set. </li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>kNN with \(k=1\)</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">knn_fit_1 &lt;- knn3(y ~ ., data = mnist_27$train, k = 1)
y_hat_knn_1 &lt;- predict(knn_fit_1, mnist_27$train, type = &quot;class&quot;)
confusionMatrix(data=y_hat_knn_1, reference=mnist_27$train$y)$overall[[&quot;Accuracy&quot;]]
</code></pre>

<pre><code>## [1] 0.998
</code></pre>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>What about the test accuracy?</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">y_hat_knn_1 &lt;- predict(knn_fit_1, mnist_27$test, type = &quot;class&quot;)
confusionMatrix(data=y_hat_knn_1, reference=mnist_27$test$y)$overall[&quot;Accuracy&quot;]
</code></pre>

<pre><code>## Accuracy 
##    0.735
</code></pre>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Picturing over-fitting</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <p><img src="figure/knn-1-overfit-1.png" title="plot of chunk knn-1-overfit" alt="plot of chunk knn-1-overfit" width="70%" /></p>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>What can we see?</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>The estimate \(\hat{p}(x_1, x_2)\) follows the training data too closely (left). </li>
<li>You can see that in the training set, boundaries have been drawn to perfectly surround a single red point in a sea of blue. </li>
<li>Because most points \((x_1, x_2)\) are unique, the prediction is either 1 or 0 and the prediction for that point is the associated label. </li>
<li>However, once we introduce the training set (right), we see that many of these small islands now have the opposite color and we end up making several incorrect predictions.</li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Over-smoothing</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Although not as badly as with the previous examples, we saw that with \(k=5\) we also over-trained.</li>
<li>Hence, we should consider a larger \(k\). </li>
<li>Let&#39;s try, as an example, a much larger number: \(k=401\). </li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Over-smoothing</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">knn_fit_401 &lt;- knn3(y ~ ., data = mnist_27$train, k = 401)
y_hat_knn_401 &lt;- predict(knn_fit_401, mnist_27$test, type = &quot;class&quot;)
confusionMatrix(data=y_hat_knn_401, reference=mnist_27$test$y)$overall[&quot;Accuracy&quot;]
</code></pre>

<pre><code>## Accuracy 
##     0.79
</code></pre>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Large \(k\) vs Linear</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>This turns out to be similar to regression:</li>
</ul>

<p><img src="figure/mnist-27-glm-est-1.png" title="plot of chunk mnist-27-glm-est" alt="plot of chunk mnist-27-glm-est" height="20%" /></p>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Large \(k\) vs Linear</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>This size of \(k\) is so large that it does not permit enough flexibility. </li>
<li>We call this <em>over-smoothing</em>. </li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Picking the \(k\) in kNN</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>So how do we pick \(k\)? </li>
<li>In principle we want to pick the \(k\) that maximizes accuracy, or minimizes the expected MSE.</li>
<li>The goal of cross validation is to estimate these quantities for any given algorithm and set of tuning parameters such as \(k\). </li>
<li>To understand why we need a special method to do this let&#39;s repeat what we did above but for different values of \(k\):</li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Coding</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Sequence of ks</li>
</ul>

<pre><code class="r">ks &lt;- seq(3, 251, 2)
</code></pre>

<ul>
<li>We do this using  <code>map_df</code> function to repeat the above for each one. </li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Coding</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">library(caret)
library(purrr)
library(tidyverse)
accuracy &lt;- map_df(ks, function(k){
  fit &lt;- knn3(y ~ ., data = mnist_27$train, k = k)

  y_hat &lt;- predict(fit, mnist_27$train, type = &quot;class&quot;)
  cm_train &lt;- confusionMatrix(data = y_hat, reference = mnist_27$train$y)
  train_error &lt;- cm_train$overall[&quot;Accuracy&quot;]

  y_hat &lt;- predict(fit, mnist_27$test, type = &quot;class&quot;)
  cm_test &lt;- confusionMatrix(data = y_hat, reference = mnist_27$test$y)
  test_error &lt;- cm_test$overall[&quot;Accuracy&quot;]

  tibble(train = train_error, test = test_error)
})
</code></pre>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Plotting accuracy</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Note that we estimate accuracy by using both the training set and the test set. </li>
<li>We can now plot the accuracy estimates for each value of \(k\):</li>
</ul>

<p><img src="figure/accuracy-vs-k-knn-1.png" alt="plot of chunk accuracy-vs-k-knn"></p>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>What can we see?</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>The estimate obtained on the training set is generally higher than the estimate obtained with the test set, with the difference larger for smaller values of \(k\). </li>
<li>This is due to over-fitting Also note that the accuracy versus \(k\) plot is quite jagged.</li>
<li>We do not expect this because small changes in \(k\) should not affect the algorithm&#39;s performance too much. </li>
<li>The jaggedness is explained by the fact that the accuracy is computed on a sample and therefore is a random variable.</li>
<li>This demonstrates why we prefer to minimize the expected loss rather than the loss we observe with one dataset. </li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Different \(k\)</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>If we were to use these estimate to pick the \(k\) that maximizes accuracy, we would use the estimates built on the test data:</li>
</ul>

<pre><code class="r">ks[which.max(accuracy$test)]
max(accuracy$test)
</code></pre>

<pre><code>## [1] 41
## [1] 0.86
</code></pre>

<ul>
<li>Another reason we need a better estimate of accuracy is that if we use the test set to pick this \(k\), we we not should expect the accompanying accuracy estimate to extrapolate to the real world. </li>
<li>This is because even here we broke a golden rule of machine learning: we selected the \(k\) using the test set. </li>
<li>Cross validation also provides an estimate that takes this into account.</li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Mathematical description of cross validation</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>When we introduced liner regression we said one goal was to minimize the MSE. 
\[
\mbox{MSE} = \mbox{E}\left\{ \frac{1}{N}\sum_{i=1}^N (\hat{Y}_i - Y_i)^2 \right\}
\]</li>
<li>When all we have at our disposal is one dataset, we can estimate the MSE with the observed MSE like this:
\[
\hat{\mbox{MSE}} = \frac{1}{N}\sum_{i=1}^N (\hat{y}_i - y_i)^2
\]</li>
<li>These two are often referred to as the <em>true error</em> and <em>apparent error</em> respectively.</li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Apparent Error</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ol>
<li>Because our data is random, the apparent error is a random variable. </li>
<li>If we train an algorithm on the same dataset that we use to compute the apparent error, we might be overfitting 

<ul>
<li>In general, when we do this, the apparent error will be an underestimate of the true error. </li>
<li>We will see an extreme example of this with k nearest neighbors.</li>
</ul></li>
</ol>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Cross validation</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Cross validation is a technique that permits us to alleviate both these problems. </li>
<li>To understand cross validation, it helps to think of the true error, a theoretical quantity, as the average of many apparent errors obtained by applying the algorithm to \(B\) new random samples of the data, none of them used to train the algorithm. </li>
<li>We think of the true error as:</li>
</ul>

<p>\[
\frac{1}{B} \sum_{b=1}^B \frac{1}{N}\sum_{i=1}^N \left(\hat{y}_i^b - y_i^b\right)^2 
\]</p>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Cross validation</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>with \(B\) a large number that can be thought of as practically infinite. </li>
<li>As already mentioned, this is a theoretical quantity because we only have available one set of outcomes: \(y_1, \dots, y_n\). </li>
<li>Cross validation is based on the idea of imitating the theoretical setup above as best we can with the data we have. </li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Cross Validation</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>To do this, we have to generate a series of different random samples. </li>
<li>There are several approaches we can use, but the general idea for all of them is to randomly generate smaller datasets that are not used for training, and instead used to estimate the true error.</li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>K-fold cross validation</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>We begin with a dataset that we work with (blue) and we wish to test on a completely new dataset (yellow)
<img src="images/cv-1.png" alt="plot of chunk unnamed-chunk-16"></li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Reality Check</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>We typically never get to see the yellow when building the model. </li>
<li>So to imitate this situation, we carve out a piece of our dataset and pretend it is an independent dataset.</li>
<li>we divide the dataset into a <em>training set</em> (blue) and a <em>test set</em> (red). </li>
<li>We will train our models exclusively on the training set and use the test set only for evaluation purposes.</li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Reality Check</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <p><img src="images/cv-3.png" alt="plot of chunk unnamed-chunk-17"></p>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>How do we do this?</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>We usually try to select a small piece of the dataset so that we have as much data as possible to train. </li>
<li>However, we also want the test set to be large so that we obtain a stable estimate of the loss without fitting an impractical number of models. </li>
<li>Typical choices are to use 10%-20% of the data for testing. </li>
<li>For each set of model parameters being considered, we we want an estimate of the MSE and then we will chose the parameters with the smallest MSE. </li>
<li>Cross validation provides this estimate.</li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Cross Validation</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>
First, before we start the cross validation procedure, it is important to fix all the algorithm parameters. </li>
<li>Although we will train the algorithm on the set of training sets, the parameters \(\lambda\) will be the same across all training sets.</li>
<li>We will use \(\hat{y}_i(\lambda)\) to denote the predictors obtained when we use parameters \(\lambda\).</li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Cross Validation</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>So, if we are going to imitate this definition:
\[
\mbox{MSE}(\lambda) = \frac{1}{B} \sum_{b=1}^B \frac{1}{N}\sum_{i=1}^N \left(\hat{y}_i^b(\lambda) - y_i^b\right)^2 
\]</li>
<li>we want to consider datasets that can be thought of as an independent random sample and we want to do this several times. </li>
<li>With K-fold cross validation, we do it \(K\) times. </li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>How?</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>We will eventually end up with \(K\) samples, but let&#39;s start by describing how to construct the first:</li>
<li> we simply pick \(M=N/K\) observations at random (we round if \(M\) is not a round number) and think of these as a random sample \(y_1^b, \dots, y_M^b\), with \(b=1\). </li>
<li>We call this the validation set:</li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Validation Set</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <p><img src="images/cv-4.png" alt="plot of chunk unnamed-chunk-18"></p>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Fit Model in Training Set</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Now we can fit the model in the training set, then compute the apparent error on the independent set:
\[
\hat{\mbox{MSE}}_b(\lambda) = \frac{1}{M}\sum_{i=1}^M \left(\hat{y}_i^b(\lambda) - y_i^b\right)^2 
\]</li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Problems?</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Note that this is just one sample and will therefore return a noisy estimate of the true error.</li>
<li>This is why we take \(K\) samples, not just one. </li>
<li>In K-cross validation, we randomly split the observations into \(K\) non-overlapping sets:</li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <article data-timings="">
    <p><img src="images/cv-5.png" alt="plot of chunk unnamed-chunk-19"></p>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Repeat</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Now we repeat the calculation above for each of these sets \(b=1,\dots,K\) and obtain \(\hat{\mbox{MSE}}_1(\lambda),\dots, \hat{\mbox{MSE}}_K(\lambda)\). </li>
<li>Then, for our final estimate, we compute the average:
\[
\hat{\mbox{MSE}}(\lambda) = \frac{1}{B} \sum_{b=1}^K \hat{\mbox{MSE}}_b(\lambda)
\]</li>
<li>A final step would be to select the \(\lambda\) that minimizes the MSE.</li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Notes</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>We now have to take into account the fact that the optimization occurred on the training data and therefore we need an estimate of our final algorithm based on data that was not used to optimize the choice. </li>
<li>Here is where we use the test set we separated early on:</li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <article data-timings="">
    <p><img src="images/cv-6.png" alt="plot of chunk unnamed-chunk-20"></p>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Cross Validation</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>We can do cross validation again:</li>
</ul>

<p><img src="images/cv-7.png" alt="plot of chunk unnamed-chunk-21"></p>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Final Notes</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>note that this means that our entire compute time gets multiplied by \(K\).</li>
<li>You will soon learn that performing this task takes time because we are performing many complex computations. </li>
<li>As a result, we are always looking for ways to reduce this time. </li>
<li>For the final evaluation, we often just use the one test set.</li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>How do we pick k?</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li> Large values of \(K\) are preferable because the training data better imitates the original dataset. </li>
<li>However, larger values of \(K\) will have much slower computation time: for example, 100-fold cross validation will be 10 times slower than 10-fold cross validation. </li>
<li>For this reason, the choices of \(K=5\) and \(K=10\) are popular.</li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Improving on Estimates?</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>One way we can improve the variance of our final estimate is to take more samples. </li>
<li>To do this, we would no longer require the training set to be partitioned into non-overlapping sets. </li>
<li>Instead, we would just pick \(K\) sets of some size at random.</li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Improving Estimates</h2>
    <hr>
  </hgroup>
  <article data-timings="">
    <ul>
<li>One popular version of this technique, at each fold, picks observations at random with replacement (which means the same observation can appear twice).</li>
<li>This approach has some advantages (not discussed here) and is generally referred to as the <em>Bootstrap</em>.</li>
<li>In fact, this is the default approach in the <strong>caret</strong> package.<br></li>
</ul>

    
    <footer class = 'logo'>
<div style="position: absolute; left: 900px; top: 600px; z-index:100">
<img src = "assets/img/publichealthlogo.png" height="100" >
</div>
</footer>
  </article>
  <!-- Presenter Notes -->
</slide>

    <slide class="backdrop"></slide>
  </slides>
  <div class="pagination pagination-small" id='io2012-ptoc' style="display:none;">
    <ul>
      <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=1 title='Cross validation'>
         1
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=2 title='Cross Validation'>
         2
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=3 title='Motivation with k-nearest neighbors'>
         3
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=4 title='Motivation with k-nearest neighbors'>
         4
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=5 title='Why K-Nearest Neighbors'>
         5
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=6 title='What are we doing?'>
         6
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=7 title='How do we do this?'>
         7
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=8 title='<code>caret</code> package in R'>
         8
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=9 title='What do we get ?'>
         9
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=10 title='What do we get ?'>
         10
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=11 title='Comparison to Linear Regression'>
         11
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=12 title='Comparison to Linear Regression'>
         12
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=13 title='Comparison to Linear Regression'>
         13
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=14 title='Comparison Plots'>
         14
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=15 title='Why does it work?'>
         15
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=16 title='Viewing Overfitting'>
         16
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=17 title='Over-fitting'>
         17
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=18 title='kNN with \(k=1\)'>
         18
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=19 title='What about the test accuracy?'>
         19
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=20 title='Picturing over-fitting'>
         20
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=21 title='What can we see?'>
         21
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=22 title='Over-smoothing'>
         22
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=23 title='Over-smoothing'>
         23
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=24 title='Large \(k\) vs Linear'>
         24
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=25 title='Large \(k\) vs Linear'>
         25
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=26 title='Picking the \(k\) in kNN'>
         26
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=27 title='Coding'>
         27
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=28 title='Coding'>
         28
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=29 title='Plotting accuracy'>
         29
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=30 title='What can we see?'>
         30
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=31 title='Different \(k\)'>
         31
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=32 title='Mathematical description of cross validation'>
         32
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=33 title='Apparent Error'>
         33
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=34 title='Cross validation'>
         34
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=35 title='Cross validation'>
         35
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=36 title='Cross Validation'>
         36
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=37 title='K-fold cross validation'>
         37
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=38 title='Reality Check'>
         38
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=39 title='Reality Check'>
         39
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=40 title='How do we do this?'>
         40
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=41 title='Cross Validation'>
         41
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=42 title='Cross Validation'>
         42
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=43 title='How?'>
         43
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=44 title='Validation Set'>
         44
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=45 title='Fit Model in Training Set'>
         45
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=46 title='Problems?'>
         46
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=47 title='NA'>
         47
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=48 title='Repeat'>
         48
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=49 title='Notes'>
         49
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=50 title='NA'>
         50
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=51 title='Cross Validation'>
         51
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=52 title='Final Notes'>
         52
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=53 title='How do we pick k?'>
         53
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=54 title='Improving on Estimates?'>
         54
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=55 title='Improving Estimates'>
         55
      </a>
    </li>
  </ul>
  </div>  <!--[if IE]>
    <script 
      src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js">  
    </script>
    <script>CFInstall.check({mode: 'overlay'});</script>
  <![endif]-->
</body>
  <!-- Load Javascripts for Widgets -->
  <script src="libraries/widgets/quiz/js/jquery.quiz.js"></script>
<script src="libraries/widgets/quiz/js/mustache.min.js"></script>
<script src="libraries/widgets/quiz/js/quiz-app.js"></script>
<script src="libraries/widgets/bootstrap/js/bootstrap.min.js"></script>
<script src="libraries/widgets/bootstrap/js/bootbox.min.js"></script>
<script src="libraries/widgets/interactive/js/ace/js/ace.js"></script>
<script src="libraries/widgets/interactive/js/opencpu-0.5.js"></script>
<script src="libraries/widgets/interactive/js/interactive.js"></script>

  <!-- MathJax: Fall back to local if CDN offline but local image fonts are not supported (saves >100MB) -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: true
      }
    });
  </script>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <!-- <script src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script> -->
  <script>window.MathJax || document.write('<script type="text/x-mathjax-config">MathJax.Hub.Config({"HTML-CSS":{imageFont:null}});<\/script><script src="libraries/widgets/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"><\/script>')
</script>
<script>  
  $(function (){ 
    $("#example").popover(); 
    $("[rel='tooltip']").tooltip(); 
  });  
  </script>  
  <!-- LOAD HIGHLIGHTER JS FILES -->
  <script src="libraries/highlighters/highlight.js/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <!-- DONE LOADING HIGHLIGHTER JS FILES -->
   
  </html>